{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming in Python for Data Science \n",
    "\n",
    "# Assignment 7: Importing Files and the Coding Style Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't learn technical subjects without hands-on practice. The assignments are an important part of the course. To submit this assignment you will need to make sure that you save your Jupyter notebook. \n",
    "\n",
    "Below are the links of 2 videos that explain:\n",
    "\n",
    "1. [How to save your Jupyter notebook](https://youtu.be/0aoLgBoAUSA) and,       \n",
    "2. [How to answer a question in a Jupyter notebook assignment](https://youtu.be/7j0WKhI3W4s).       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Learning Goals:\n",
    "\n",
    "By the end of the module, students are expected to:\n",
    "\n",
    "- Describe what Python libraries are, as well as explain when and why they are useful.\n",
    "- Identify where code can be improved concerning variable names, magic numbers, comments and whitespace.\n",
    "- Write code that is human readable and follows the black style guide.\n",
    "- Import files from other directories.\n",
    "- Use [`pytest`](https://docs.pytest.org/en/stable/) to check a function's tests.\n",
    "- When running [`pytest`](https://docs.pytest.org/en/stable/), explain how pytest finds the associated test functions.\n",
    "- Explain how the Python debugger can help rectify your code.\n",
    "\n",
    "This assignment covers [Module 7](https://prog-learn.mds.ubc.ca/en/module7) of the online course. You should complete this module before attempting this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any place you see `...`, you must fill in the function, variable, or data to complete the code. Substitute the `None` and the `raise NotImplementedError # No Answer - remove if you provide an answer` with your completed code and answers then proceed to run the cell!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of the questions in this assignment will have hidden tests. This means that no feedback will be given as to the correctness of your solution. It will be left up to you to decide if your answer is sufficiently correct. These questions are worth 2 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries needed for this lab\n",
    "import test_assignment7 as t\n",
    "from hashlib import sha1\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.   Importing libraries   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1(a)** <br> {points: 1}  \n",
    "\n",
    "Import the `pandas` library and name it `pd` in the worksheet environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e7a239b989f8065dc779eac5c0db120",
     "grade": false,
     "grade_id": "cell-33212a70ac92beea",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f685f2f8a2ce8ecc6e254989ff98820",
     "grade": true,
     "grade_id": "cell-932eba7b75fc58b2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1a(dir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1(b)** <br> {points: 1}  \n",
    "\n",
    "Import the Altair library into the worksheet enviroment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36271cc448c00e70899b7d28563bf9bb",
     "grade": false,
     "grade_id": "cell-2fb5b8e075bbd416",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61befda99759541fa776cd5b609d4863",
     "grade": true,
     "grade_id": "cell-eca513c226d7f7f2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1b(dir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1(c)** <br> {points: 1}  \n",
    "\n",
    "From the `numpy` library, only import the `arange()` function using the keywork `from`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e04a06ede5f30fe883b4bc81409da5a4",
     "grade": false,
     "grade_id": "cell-e99cf81fa9d22012",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from numpy import arange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a8ebfc54a36aa71ca44dd915c08591d",
     "grade": true,
     "grade_id": "cell-cf28d80fe773f520",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1c()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Working with other files  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(a)** <br> {points: 1}  \n",
    "\n",
    "Load in the `chopped.csv` file from the data folder and save it as an object named `chopped`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d5320b231dfcaedd4e56b3582c60daa",
     "grade": false,
     "grade_id": "cell-6134753661931f24",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "chopped = pd.read_csv('data/chopped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec65ca40ff824242d121b0d208b4070e",
     "grade": true,
     "grade_id": "cell-746bfa633c7af0a3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2a(chopped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(b)** <br> {points: 1}  \n",
    "\n",
    "Import the the function `sample_dataframe()` (that we created in Assignment 6) from `sampling.py` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3390bf4c0478081f9033c3610846add3",
     "grade": false,
     "grade_id": "cell-a60b50fcb75443d2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sampling import sample_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0cd337866dc4a04621d25f3fbe0ebce2",
     "grade": true,
     "grade_id": "cell-635d330803423f4e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2b(dir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(c)** <br> {points: 2}  \n",
    "\n",
    "To refresh yourself on what the function `sample_dataframe()` does, inspect the function docstring.  \n",
    "\n",
    "Which of the following is the correct way to inspect the docstring of the function `sample_dataframe()`?     \n",
    "*Hint: Try it out yourself*\n",
    "\n",
    "A) `?sample.sample_dataframe`\n",
    "\n",
    "B) `?sample.sample_dataframe()` \n",
    "\n",
    "C) `?sample_dataframe`\n",
    "\n",
    "D) `?sample_dataframe()`\n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer2_c`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b37ea0df60619ac283eb5e272a0aa8c4",
     "grade": false,
     "grade_id": "cell-7fcb41f86f7ea257",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_c = 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f518f3ab0ad13f24297344e661616fb",
     "grade": true,
     "grade_id": "cell-35291c2eeae630fd",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note that this test has been hidden intentionally.\n",
    "# It will provide no feedback as to the correctness of your answers.\n",
    "# Thus, it is up to you to decide if your answer is sufficiently correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0msample_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrouping_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Given a dataframe, return a smaller sample of the dataframe\n",
       "sampling N rows from each specified group\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data : pandas.core.frame.DataFrame\n",
       "    The dataframe to sample from\n",
       "grouping_col : str\n",
       "    The column to filter our condition on\n",
       "N : int, optional\n",
       "    The number of rows to sample from each group (The default value is 1\n",
       "    which implies a single observation)\n",
       "\n",
       "Returns\n",
       "-------\n",
       "pandas.core.frame.DataFrame\n",
       "    The new sampled dataframe\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> sample_dataframe(pokemon, 'legendary'])\n",
       "    name     deck_no  attack  defense  type    gen  legendary\n",
       "411 Burmy     412     29        45      bug     4      0\n",
       "640 Tornadus  641     100       80      flying  5      1\n",
       "\u001b[0;31mFile:\u001b[0m      ~/prog-python-data-science-students/release/assignment7/sampling.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?sample_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(d)** <br> {points: 1}  \n",
    "\n",
    "Based on the docstring, which parameter is optional?       \n",
    "Answer the parameter name as a `str` in the object `answer2_d`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d1ef9c2fe2ed9b7c9d97ecc9146b943",
     "grade": false,
     "grade_id": "cell-e8920e5152e7e308",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_d = 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b33e02e909283893e74a4671d385864b",
     "grade": true,
     "grade_id": "cell-5821de7729f52862",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2d(answer2_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(e)** <br> {points: 1}  \n",
    "\n",
    "Based on the docstring, which parameter accepts data types of `str`?      \n",
    "\n",
    "Answer the parameter name as a `str` in the object `answer2_e`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0e24962220dde0237ba12efbd484be1",
     "grade": false,
     "grade_id": "cell-e676311b515dde12",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_e = 'grouping_col'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b425c2b493cee2b74194928aeff2432",
     "grade": true,
     "grade_id": "cell-3fd7084db8d73672",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2e(answer2_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(f)** <br> {points: 1}  \n",
    "\n",
    "Sample two rows from each season from the `chopped` dataframe using your function `sample_dataframe`.     \n",
    "\n",
    "Save this in an object named `chopped_sample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "882ac872c1be42d6674b60036e238c2c",
     "grade": false,
     "grade_id": "cell-6299480a9da3c466",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "chopped_sample = sample_dataframe(chopped, 'season', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98ec1de9cca0165ef824e2d7bf3b5ac1",
     "grade": true,
     "grade_id": "cell-a3352eba01015292",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2f(chopped_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using Pytest\n",
    "\n",
    "We have provided you with another file called `test_sampling.py` which contains multiple functions that test if our `sample_dataframe()` function is working properly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3(a)** <br> {points: 1}  \n",
    "\n",
    "The tests for `sample_dataframe()` are located in a different file than the function which means we will need to import the function from our `sampling.py` file at the top of `test_sampling.py`. \n",
    "\n",
    "Open `test_sampling.py` and on line 2, write code to import the `sample_dataframe()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3cade35fe5e7e6d5bb01615bec546eaa",
     "grade": true,
     "grade_id": "cell-ae85375476286d96",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3a()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6a179132ad8eb5bbe5f4881b9e1cf29f",
     "grade": false,
     "grade_id": "cell-6b432fa592bfb361",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3(b)** <br>\n",
    "\n",
    "We are going to do things a little differently then in the lesson here. \n",
    "Using `pytest` in a jupyter notebook, we can check if all the tests in `test_sampling.py` pass using the code `!pytest test_sampling.py` in a code cell. \n",
    "\n",
    "\n",
    "Try it out in the cell below and answer the following multiple choice questions regarding the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.5, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\n",
      "rootdir: /home/jupyter/prog-python-data-science-students/release/assignment7\n",
      "plugins: anyio-3.2.1, dash-1.20.0\n",
      "collected 6 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "test_sampling.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                  [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m________________________________ test_sd_cherry ________________________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_sd_cherry\u001b[39;49;00m():\n",
      "        raw = {\u001b[33m'\u001b[39;49;00m\u001b[33mid\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[94m1873\u001b[39;49;00m, \u001b[94m4913\u001b[39;49;00m, \u001b[94m4801\u001b[39;49;00m, \u001b[94m4540\u001b[39;49;00m, \u001b[94m3581\u001b[39;49;00m,\n",
      "                       \u001b[94m4534\u001b[39;49;00m, \u001b[94m1934\u001b[39;49;00m, \u001b[94m4944\u001b[39;49;00m, \u001b[94m1983\u001b[39;49;00m, \u001b[94m1266\u001b[39;49;00m],\n",
      "               \u001b[33m'\u001b[39;49;00m\u001b[33mname\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m'\u001b[39;49;00m\u001b[33mEnglish Oak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mHigan Cherry\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mWillow Oak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[33m'\u001b[39;49;00m\u001b[33mYoshino Cherry\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mRed Oak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mKindred Spirit Oak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[33m'\u001b[39;49;00m\u001b[33mGarry Oak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mAccolade Cherry\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mSnow Goose Cherry\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[33m'\u001b[39;49;00m\u001b[33mEvergreen Oak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mneighbourhood\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m'\u001b[39;49;00m\u001b[33mSunset\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[33m'\u001b[39;49;00m\u001b[33mWest end\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[33m'\u001b[39;49;00m\u001b[33mKitsilano\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mSunset\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                                  \u001b[33m'\u001b[39;49;00m\u001b[33mArbutus-ridge\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[33m'\u001b[39;49;00m\u001b[33mArbutus-ridge\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mKitsilano\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                                  \u001b[33m'\u001b[39;49;00m\u001b[33mWest end\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[33m'\u001b[39;49;00m\u001b[33mKitsilano\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mArbutus-ridge\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mtype\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m'\u001b[39;49;00m\u001b[33mOak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mCherry\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mOak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mCherry\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mOak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                         \u001b[33m'\u001b[39;49;00m\u001b[33mOak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mOak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mCherry\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mCherry\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mOak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mdiameter\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[94m9.0\u001b[39;49;00m, \u001b[94m27.0\u001b[39;49;00m, \u001b[94m3.0\u001b[39;49;00m, \u001b[94m22.0\u001b[39;49;00m, \u001b[94m3.0\u001b[39;49;00m,\n",
      "                             \u001b[94m6.5\u001b[39;49;00m, \u001b[94m12.0\u001b[39;49;00m, \u001b[94m18.0\u001b[39;49;00m, \u001b[94m8.5\u001b[39;49;00m, \u001b[94m23.0\u001b[39;49;00m]}\n",
      "        helper_data = pd.DataFrame.from_dict(raw)\n",
      "    \n",
      "        sampler = sample_dataframe(helper_data, \u001b[33m'\u001b[39;49;00m\u001b[33mtype\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[90m# Tests that there are only 1 row of type \"Cherry\"\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m sampler[sampler[\u001b[33m'\u001b[39;49;00m\u001b[33mtype\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33mCherry\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].shape[\u001b[94m0\u001b[39;49;00m] == \u001b[94m3\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mThe dataframe should only have 1 row of type \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mcherry\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: The dataframe should only have 1 row of type 'cherry'\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert 1 == 3\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_sampling.py\u001b[0m:132: AssertionError\n",
      "=========================== short test summary info ============================\n",
      "FAILED test_sampling.py::test_sd_cherry - AssertionError: The dataframe shoul...\n",
      "\u001b[31m========================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m5 passed\u001b[0m\u001b[31m in 1.13s\u001b[0m\u001b[31m ==========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_sampling.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3(b-i)** <br> {points: 1}  \n",
    "\n",
    "How many of the tests from `test_sampling.py` passed?      \n",
    "*Assign the correct answer to an object called `tests_passed`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "547fbada2f64cffe0d00e10fbe452d9a",
     "grade": false,
     "grade_id": "cell-fb3fd2b5482fdc05",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tests_passed = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3b1813b96d691c1eaf9f317d381a525",
     "grade": true,
     "grade_id": "cell-c687047bada4fe95",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3bi(tests_passed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3(b-ii)** <br> {points: 2}  \n",
    "\n",
    "How many of the tests from `test_sampling.py` failed?      \n",
    "*Assign the correct answer to an object called `tests_failed`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a651b9fbb2e7b2a5b7300f40a4241b3f",
     "grade": false,
     "grade_id": "cell-1202fc67d62b1792",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tests_failed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2b81476073bd44de4e8817f9093fb0d",
     "grade": true,
     "grade_id": "cell-abcdd5212ce8810c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note that this test has been hidden intentionally.\n",
    "# It will provide no feedback as to the correctness of your answers.\n",
    "# Thus, it is up to you to decide if your answer is sufficiently correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3(b-iii)** <br> {points: 1}  \n",
    "\n",
    "Name a test that did not pass.   \n",
    "*Assign the correct answer to an object called `failed_name`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c18a537e1b9d742949bb3e75ecaa94a9",
     "grade": false,
     "grade_id": "cell-67209bf44bc4b370",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "failed_name = 'test_sd_cherry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0480cd9b22932ceeef90d6c2fb046aa5",
     "grade": true,
     "grade_id": "cell-3d2823a898a6289a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3biii(failed_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Black and Flake8 Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(a)** <br>\n",
    "\n",
    "Run Flake8 on our `sampling.py` file in the cell below or in the terminal and answer the questions that follow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flake8 sampling.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(a-i)** <br> {points: 1}  \n",
    "\n",
    "How many formatting issues did flake8 recognize in the `sampling.py` file?      \n",
    "*Assign the correct answer to an object called `answer4_ai`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d4970e87ebc89bbab5933e526bc9d56",
     "grade": false,
     "grade_id": "cell-27db9cfd0445f2ef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_ai = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca9cedde3d5ecbc3f9cff73e87bc888b",
     "grade": true,
     "grade_id": "cell-da78b4046f2a5291",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_4ai(answer4_ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(a-ii)** <br> {points: 1}  \n",
    "\n",
    "How many `W291 trailing whitespace` issues are there? (We will talk a little bit about trailing and leading white space in Module 8)       \n",
    "*Assign the correct answer to an object called `answer4_aii`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a12ea403bfdb2232c6d38b8c1b077c5",
     "grade": false,
     "grade_id": "cell-4380df8c2f16c985",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_aii = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69531d3d00c1ce4dbdac5fb7d33de02e",
     "grade": true,
     "grade_id": "cell-ab23a0ce59a092f1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_4aii(answer4_aii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(a-iii)** <br> {points: 1}  \n",
    "\n",
    "\n",
    "Which of the following is the formatting issue that occurs on line 36?     \n",
    "\n",
    "\n",
    "A) `E222 multiple spaces after operator`\n",
    "\n",
    "B) `W293 blank line contains whitespace`\n",
    "\n",
    "C) `W291 trailing whitespace`\n",
    "\n",
    "D) `E251 unexpected spaces around keyword / parameter equals` \n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer4_aiii`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8ba94996c89f41c55e0462426fde910",
     "grade": false,
     "grade_id": "cell-4cdb5bce57b584a7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_aiii = 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e8d3aab045252b408d7476ca95207e2",
     "grade": true,
     "grade_id": "cell-7775bd41eaf54724",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_4aiii(answer4_aiii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(b)**  {points: 1}  \n",
    "\n",
    "Run `black` on our `sampling.py` file in the cell below or in the terminal and answer the questions that follow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAll done! ‚ú® üç∞ ‚ú®\u001b[0m\n",
      "1 file left unchanged.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!black sampling.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which code would you use in a Jupyter code cell to run Black?\n",
    "\n",
    "A) `black sampling.py`\n",
    "\n",
    "B) `!black sampling.py` \n",
    "\n",
    "C) `sampling.black()`\n",
    "\n",
    "D) `black.sampling()`\n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer4_b`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84c9e855c345eac9d7fd09bd3f7f8c1f",
     "grade": false,
     "grade_id": "cell-10e4f5655e22c244",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_b = 'B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76e0feef20e3e846229cb069767abe38",
     "grade": true,
     "grade_id": "cell-c9348b9faa589abf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_4b(answer4_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(c)** <br> {points: 2}  \n",
    "\n",
    "Now that we have reformatted our `sampling.py` file, let's rerun flake8 just as we did before as see how many of our formatting issues have been fixed and answer the question below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flake8 sampling.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many formatting issues are we left with after re-runing flake8 after formatting `sampling.py` using the `black` style guide?\n",
    "\n",
    "*Assign the correct answer to an object called `answer4_c`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4bee54132eb4c6c8c098d8c36a9eabec",
     "grade": false,
     "grade_id": "cell-a94532cb877f86ba",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_c = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "602952b54c4dc96a00ec19e3e1b64280",
     "grade": true,
     "grade_id": "cell-b9a92e7037aad0c9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note that this test has been hidden intentionally.\n",
    "# It will provide no feedback as to the correctness of your answers.\n",
    "# Thus, it is up to you to decide if your answer is sufficiently correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Style Guide - Comments and Variable Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5(a)** <br> {points: 1}  \n",
    "\n",
    "Which of the following names is most fitting for an object that contains a list of column names from a dataframe named `metals`? \n",
    "\n",
    "A) `metal_columns`\n",
    "\n",
    "B) `columnsfrommetaldataframe`\n",
    "\n",
    "C) `list`\n",
    "\n",
    "D) `c_metals` \n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer5_a`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea99287d09106ebc9636ea5fdb831838",
     "grade": false,
     "grade_id": "cell-f50baa637608027f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer5_a = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f4cacdab2a71d36acc7317f216f4a80",
     "grade": true,
     "grade_id": "cell-141b5df587a3cc3e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_5a(answer5_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5(b)** <br> {points: 1}  \n",
    "\n",
    "Which of the following names is the best fitting for object containing a dataframe containing different lightbulb types?\n",
    "\n",
    "A) `LIGHTBULBS`\n",
    "\n",
    "B) `dataframe_where_lightbulbs_data_stored`\n",
    "\n",
    "C) `data`\n",
    "\n",
    "D) `lightbulb_df` \n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer5_b`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "efffe815faf74591e38eb4b46312af57",
     "grade": false,
     "grade_id": "cell-1ac2beeec7f1258d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer5_b = 'D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2d999013dd895239cbf204bb401bb5f",
     "grade": true,
     "grade_id": "cell-5a33f1e90db1379f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_5b(answer5_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5(c)** <br> {points: 2}  \n",
    "\n",
    "Which of the following is NOT a reasonable comment to include in your code?\n",
    "\n",
    "A) `# Keep this line of code in, or the function will break mysteriously`\n",
    "\n",
    "B) `# Rename columns to shorter column names`\n",
    "\n",
    "C) `# This assigns all the values greater than 100 a value of 100.`\n",
    "\n",
    "D) `# TODO: Fix this next part so it's more readable and doesn't include magic numbers` \n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer5_c`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8b780f05c3efad8ea5202822858169d",
     "grade": false,
     "grade_id": "cell-58ce14551039cefd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer5_c = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc374f8eae271b873f35ee34826fc662",
     "grade": true,
     "grade_id": "cell-67d88876daa123c2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note that this test has been hidden intentionally.\n",
    "# It will provide no feedback as to the correctness of your answers.\n",
    "# Thus, it is up to you to decide if your answer is sufficiently correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5(d)** <br> {points: 2}  \n",
    "\n",
    "Below is a function that plots a histogram of a specified quantitative column.\n",
    "We want you to identify the 4 poorly designed elements within this function, and rewrite/rename them to something that is more appropriate. \n",
    "\n",
    "Copy and paste the function into the cell that follows it and then make your desired changes.\n",
    "\n",
    "*Hint: The function name does not need to be changed* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "\n",
    "def column_histogram(data, column_name):\n",
    "    \"\"\"\n",
    "    \n",
    "    Given a dataframe, this function creates a histogram\n",
    "    of the values from a specified column\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas.core.frame.DataFrame\n",
    "        The dataframe to filter\n",
    "    column_name : str\n",
    "        The column values to plot\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    altair.vegalite.v4.api.Chart \n",
    "        the plotted histogram\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> column_histogram(chopped, \"season\")\n",
    "    altair.vegalite.v4.api.Chart \n",
    "    \"\"\"\n",
    "    \n",
    "    # This checks if the data variable is of type pd.dataframe\n",
    "    if not isinstance(data, pd.DataFrame): \n",
    "        raise TypeError(\"The data argument is not of type DataFrame\")   \n",
    "    \n",
    "    # This checks if the column dtype of column_name \n",
    "    cs = column_name + \":Q\"\n",
    "    \n",
    "    # This makes a histogram and plots the values of column_name frequency, it could be useful. \n",
    "    histogram_plot_of_column_name = alt.Chart(data).mark_bar().encode(\n",
    "                                        alt.X( cs, bin=True),\n",
    "                                              y='count()',\n",
    "                                    )\n",
    "    \n",
    "    # This function now returns a histogram \n",
    "    return histogram_plot_of_column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79d4f1778c613d7ac02986673ef33e5d",
     "grade": false,
     "grade_id": "cell-4e57ff3c843e88ed",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def column_histogram(data, column_name:str):\n",
    "    \"\"\"\n",
    "    \n",
    "    Given a dataframe, this function creates a histogram\n",
    "    of the values from a specified column\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas.core.frame.DataFrame\n",
    "        The dataframe to filter\n",
    "    column_name : str\n",
    "        The column values to plot\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    altair.vegalite.v4.api.Chart \n",
    "        the plotted histogram\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> column_histogram(chopped, \"season\")\n",
    "    altair.vegalite.v4.api.Chart \n",
    "    \"\"\"\n",
    "    \n",
    "    # Checks if data variable is of type pd.dataframe\n",
    "    if not isinstance(data, pd.DataFrame): \n",
    "        raise TypeError(\"The data argument is not of type DataFrame\")   \n",
    "    \n",
    "    # Checks the column dtype of column_name   \n",
    "    coltype = column_name + \":Q\"\n",
    "    \n",
    "    # Makes a histogram and plots the values of column_name frequency \n",
    "    hist_plot = alt.Chart(data).mark_bar().encode(\n",
    "                                        alt.X(coltype, bin=True),\n",
    "                                              y='count()',\n",
    "                                    )\n",
    "    return hist_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c87ea3309c00598248532b21c9aec546",
     "grade": true,
     "grade_id": "cell-c8c1a1322f269763",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_5d(column_histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before submitting your assignment please do the following:\n",
    "\n",
    "- Read through your solutions\n",
    "- **Restart your kernel and clear output and rerun your cells from top to bottom** \n",
    "- Makes sure that none of your code is broken \n",
    "- Verify that the tests from the questions you answered have obtained the output \"Success\"\n",
    "\n",
    "This is a simple way to make sure that you are submitting all the variables needed to mark the assignment. This method should help avoid losing marks due to changes in your environment.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributions\n",
    "- UBC's original STAT545 - [Stat545 by Jenny Bryan](https://stat545.com/)\n",
    "- MDS DSCI 523 - Data Wrangling course - [MDS's GitHub website](hhttps://ubc-mds.github.io/) \n",
    "- Chopped Dataset - [Kaggle](https://www.kaggle.com/jeffreybraun/chopped-10-years-of-episode-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Debriefing\n",
    "\n",
    "If this video is not showing up below, click on the cell and click the ‚ñ∂ button in the toolbar above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"854\"\n",
       "            height=\"480\"\n",
       "            src=\"https://www.youtube.com/embed/hBGFNWtYoYw\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7f51bffbb040>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('hBGFNWtYoYw', width=854, height=480)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
